{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División del conjunto de datos\n",
    "En este notebook, nos enfocaremos en la división del conjunto de datos oceanográficos en conjuntos de entrenamiento, validación y prueba. Es crucial que esta división respete las estaciones del año, asegurando que cada conjunto contenga ejemplos de todas las estaciones sin solapamientos temporales. Esto garantizará que nuestros modelos de aprendizaje profundo puedan generalizar adecuadamente a datos no vistos, manteniendo la estacionalidad de los fenómenos oceanográficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "\n",
    "dataset = xr.open_dataset(\"D://Aaron//cmems_mod_glo_phy_my_0.083deg_P1D-m_6years_thetao_v3.nc\")\n",
    "lsm = xr.open_dataset(\"D://Aaron//datos_mascara.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Preparación de las estaciones del año\n",
    "\n",
    "Asignamos a cada instancia temporal su estación correspondiente para facilitar una división equilibrada del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para asignar estación según el mes\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "# Aplicar la función get_season al dataset\n",
    "dataset['season'] = xr.apply_ufunc(\n",
    "    np.vectorize(get_season),\n",
    "    dataset['time'].dt.month,\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[str]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Función para dividir el dataset\n",
    "\n",
    "Definimos una función que divide el dataset según proporciones especificadas y verifica que cada conjunto tenga ejemplos de todas las estaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_time(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Divide el dataset en entrenamiento, validación y prueba asegurando que todas las estaciones estén\n",
    "    representadas en cada conjunto y no haya solapamientos temporales.\n",
    "\n",
    "    Args:\n",
    "        dataset (xr.Dataset): El dataset con la dimensión 'time'.\n",
    "        train_ratio (float): Proporción de datos para el conjunto de entrenamiento.\n",
    "        val_ratio (float): Proporción de datos para el conjunto de validación.\n",
    "        test_ratio (float): Proporción de datos para el conjunto de prueba.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset (xr.Dataset): Conjunto de entrenamiento con todas las estaciones.\n",
    "        val_dataset (xr.Dataset): Conjunto de validación con todas las estaciones.\n",
    "        test_dataset (xr.Dataset): Conjunto de prueba con todas las estaciones.\n",
    "    \"\"\"\n",
    "    # Total de puntos temporales en el dataset\n",
    "    num_times = len(dataset['time'])\n",
    "    \n",
    "    # Calcular los índices para dividir los datos\n",
    "    train_index = int(train_ratio * num_times)\n",
    "    val_index = int(val_ratio * num_times)\n",
    "    \n",
    "    # Crear los conjuntos secuencialmente por tiempo (sin solapamiento)\n",
    "    train_dataset = dataset.isel(time=slice(0, train_index))\n",
    "    val_dataset = dataset.isel(time=slice(train_index, train_index + val_index))\n",
    "    test_dataset = dataset.isel(time=slice(train_index + val_index, num_times))\n",
    "\n",
    "    # Asegurar que cada conjunto tenga ejemplos de todas las estaciones\n",
    "    def ensure_all_seasons(dataset):\n",
    "        seasons_present = np.unique(dataset['season'].values)\n",
    "        missing_seasons = set(['winter', 'spring', 'summer', 'fall']) - set(seasons_present)\n",
    "        if missing_seasons:\n",
    "            raise ValueError(f\"El dataset no tiene datos de las estaciones: {missing_seasons}\")\n",
    "        return dataset\n",
    "    \n",
    "    train_dataset = ensure_all_seasons(train_dataset)\n",
    "    val_dataset = ensure_all_seasons(val_dataset)\n",
    "    test_dataset = ensure_all_seasons(test_dataset)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Aplicación de la función de división\n",
    "\n",
    "Dividimos el dataset utilizando las proporciones estándar de 70% para entrenamiento, 15% para validación y 15% para prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función para dividir el dataset\n",
    "train_dataset, val_dataset, test_dataset = split_by_time(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Verificación de la división\n",
    "\n",
    "Es fundamental verificar que la división se haya realizado correctamente, tanto en términos de tamaños como en la representación de todas las estaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamaños de los conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento: 1790 instancias temporales\n",
      "Conjunto de validación: 383 instancias temporales\n",
      "Conjunto de prueba: 385 instancias temporales\n"
     ]
    }
   ],
   "source": [
    "# Imprimir tamaños de los conjuntos\n",
    "print(f\"Conjunto de entrenamiento: {len(train_dataset['time'])} instancias temporales\")\n",
    "print(f\"Conjunto de validación: {len(val_dataset['time'])} instancias temporales\")\n",
    "print(f\"Conjunto de prueba: {len(test_dataset['time'])} instancias temporales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rangos de tiempo de cada conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango de tiempo del conjunto de entrenamiento: 2014-01-01T00:00:00.000000000 a 2018-11-25T00:00:00.000000000\n",
      "Rango de tiempo del conjunto de validación: 2018-11-26T00:00:00.000000000 a 2019-12-13T00:00:00.000000000\n",
      "Rango de tiempo del conjunto de prueba: 2019-12-14T00:00:00.000000000 a 2021-01-01T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "# Imprimir rangos de tiempo de cada conjunto\n",
    "print(f\"Rango de tiempo del conjunto de entrenamiento: {train_dataset['time'].values[0]} a {train_dataset['time'].values[-1]}\")\n",
    "print(f\"Rango de tiempo del conjunto de validación: {val_dataset['time'].values[0]} a {val_dataset['time'].values[-1]}\")\n",
    "print(f\"Rango de tiempo del conjunto de prueba: {test_dataset['time'].values[0]} a {test_dataset['time'].values[-1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los conjuntos están ordenados cronológicamente sin solapamientos, lo que evita fugas de información temporal entre ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Verificación de la representación de estaciones\n",
    "Nos aseguramos de que cada conjunto contenga datos de todas las estaciones del año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento:\n",
      "Todas las estaciones están representadas.\n",
      "\n",
      "Conjunto de validación:\n",
      "Todas las estaciones están representadas.\n",
      "\n",
      "Conjunto de prueba:\n",
      "Todas las estaciones están representadas.\n"
     ]
    }
   ],
   "source": [
    "# Función para verificar la presencia de todas las estaciones\n",
    "def check_seasons(dataset):\n",
    "    seasons = set(dataset['season'].values)\n",
    "    missing_seasons = set(['winter', 'spring', 'summer', 'fall']) - seasons\n",
    "    if missing_seasons:\n",
    "        print(f\"Faltan las siguientes estaciones: {missing_seasons}\")\n",
    "    else:\n",
    "        print(\"Todas las estaciones están representadas.\")\n",
    "\n",
    "# Verificar en cada conjunto\n",
    "print(\"Conjunto de entrenamiento:\")\n",
    "check_seasons(train_dataset)\n",
    "\n",
    "print(\"\\nConjunto de validación:\")\n",
    "check_seasons(val_dataset)\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "check_seasons(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La verificación confirma que cada conjunto incluye datos de invierno, primavera, verano y otoño, lo cual es esencial para que el modelo aprenda patrones estacionales y generalice correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "Hemos realizado una división cuidadosa del conjunto de datos, asegurando que cada subconjunto (entrenamiento, validación y prueba) contenga ejemplos de todas las estaciones del año y que no existan solapamientos temporales entre ellos. Esta estrategia es fundamental para entrenar modelos robustos y confiables en el contexto de datos temporales y estacionales, como los oceanográficos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aurora_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

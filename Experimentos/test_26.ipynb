{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introducción**\n",
    "\n",
    "En este cuaderno se lleva a cabo el **Experimento 2** con el modelo **Aurora**, en el que se **congelan todos los parámetros** de la red excepto los del **decodificador**, entrenando solo esa parte final para un ajuste más específico. El aprendizaje se realiza con:\n",
    "\n",
    "- **Learning Rate** = `1e-4`\n",
    "- **batch_size** = `8`\n",
    "- **Epochs** = `30`\n",
    "\n",
    "Esta estrategia permite afinar el decodificador sin modificar las representaciones aprendidas por las capas anteriores del modelo, reduciendo así el cómputo y evitando sobreajustes en capas más profundas que ya han sido entrenadas previamente.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Víctor\\Desktop\\TFG-Victor\\deep_ocean_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 32GB\n",
       "Dimensions:    (depth: 49, latitude: 180, longitude: 180, time: 2558)\n",
       "Coordinates:\n",
       "  * depth      (depth) float32 196B 0.494 1.541 2.646 ... 4.833e+03 5.275e+03\n",
       "  * latitude   (latitude) float32 720B 19.58 19.67 19.75 ... 34.33 34.42 34.5\n",
       "  * longitude  (longitude) float32 720B -20.92 -20.83 -20.75 ... -6.083 -6.0\n",
       "  * time       (time) datetime64[ns] 20kB 2014-01-01 2014-01-02 ... 2021-01-01\n",
       "Data variables:\n",
       "    thetao     (time, depth, latitude, longitude) float64 32GB ...\n",
       "Attributes: (12/25)\n",
       "    Conventions:               CF-1.4\n",
       "    bulletin_date:             2021-07-07 00:00:00\n",
       "    bulletin_type:             operational\n",
       "    comment:                   CMEMS product\n",
       "    domain_name:               GL12\n",
       "    easting:                   longitude\n",
       "    ...                        ...\n",
       "    references:                http://www.mercator-ocean.fr\n",
       "    source:                    MERCATOR GLORYS12V1\n",
       "    title:                     daily mean fields from Global Ocean Physics An...\n",
       "    z_max:                     5727.9169921875\n",
       "    z_min:                     0.49402499198913574\n",
       "    copernicusmarine_version:  1.3.3</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-c32326f3-75ed-45a7-8582-5f178acd320d' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-c32326f3-75ed-45a7-8582-5f178acd320d' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>depth</span>: 49</li><li><span class='xr-has-index'>latitude</span>: 180</li><li><span class='xr-has-index'>longitude</span>: 180</li><li><span class='xr-has-index'>time</span>: 2558</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-31b8de3b-41cc-4b2a-9b82-9c1a61582330' class='xr-section-summary-in' type='checkbox'  checked><label for='section-31b8de3b-41cc-4b2a-9b82-9c1a61582330' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>depth</span></div><div class='xr-var-dims'>(depth)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.494 1.541 ... 4.833e+03 5.275e+03</div><input id='attrs-9a8475e2-7d67-4f02-bd93-acf104cdc8a1' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9a8475e2-7d67-4f02-bd93-acf104cdc8a1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4a30b77c-b580-492a-98cf-2924ea74b6a3' class='xr-var-data-in' type='checkbox'><label for='data-4a30b77c-b580-492a-98cf-2924ea74b6a3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>Z</dd><dt><span>long_name :</span></dt><dd>Depth</dd><dt><span>positive :</span></dt><dd>down</dd><dt><span>standard_name :</span></dt><dd>depth</dd><dt><span>unit_long :</span></dt><dd>Meters</dd><dt><span>units :</span></dt><dd>m</dd><dt><span>valid_max :</span></dt><dd>5274.784</dd><dt><span>valid_min :</span></dt><dd>0.494025</dd></dl></div><div class='xr-var-data'><pre>array([4.940250e-01, 1.541375e+00, 2.645669e+00, 3.819495e+00, 5.078224e+00,\n",
       "       6.440614e+00, 7.929560e+00, 9.572997e+00, 1.140500e+01, 1.346714e+01,\n",
       "       1.581007e+01, 1.849556e+01, 2.159882e+01, 2.521141e+01, 2.944473e+01,\n",
       "       3.443415e+01, 4.034405e+01, 4.737369e+01, 5.576429e+01, 6.580727e+01,\n",
       "       7.785385e+01, 9.232607e+01, 1.097293e+02, 1.306660e+02, 1.558507e+02,\n",
       "       1.861256e+02, 2.224752e+02, 2.660403e+02, 3.181274e+02, 3.802130e+02,\n",
       "       4.539377e+02, 5.410889e+02, 6.435668e+02, 7.633331e+02, 9.023393e+02,\n",
       "       1.062440e+03, 1.245291e+03, 1.452251e+03, 1.684284e+03, 1.941893e+03,\n",
       "       2.225078e+03, 2.533336e+03, 2.865703e+03, 3.220820e+03, 3.597032e+03,\n",
       "       3.992484e+03, 4.405224e+03, 4.833291e+03, 5.274784e+03], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>19.58 19.67 19.75 ... 34.42 34.5</div><input id='attrs-bd87e157-956f-4dd7-b367-d1e1e896ce75' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-bd87e157-956f-4dd7-b367-d1e1e896ce75' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fdd6491b-1888-426e-9649-876999c28a51' class='xr-var-data-in' type='checkbox'><label for='data-fdd6491b-1888-426e-9649-876999c28a51' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>Y</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>step :</span></dt><dd>0.08333587646484375</dd><dt><span>unit_long :</span></dt><dd>Degrees North</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>valid_max :</span></dt><dd>34.5</dd><dt><span>valid_min :</span></dt><dd>19.583334</dd></dl></div><div class='xr-var-data'><pre>array([19.583334, 19.666666, 19.75    , 19.833334, 19.916666, 20.      ,\n",
       "       20.083334, 20.166666, 20.25    , 20.333334, 20.416666, 20.5     ,\n",
       "       20.583334, 20.666666, 20.75    , 20.833334, 20.916666, 21.      ,\n",
       "       21.083334, 21.166666, 21.25    , 21.333334, 21.416666, 21.5     ,\n",
       "       21.583334, 21.666666, 21.75    , 21.833334, 21.916666, 22.      ,\n",
       "       22.083334, 22.166666, 22.25    , 22.333334, 22.416666, 22.5     ,\n",
       "       22.583334, 22.666666, 22.75    , 22.833334, 22.916666, 23.      ,\n",
       "       23.083334, 23.166666, 23.25    , 23.333334, 23.416666, 23.5     ,\n",
       "       23.583334, 23.666666, 23.75    , 23.833334, 23.916666, 24.      ,\n",
       "       24.083334, 24.166666, 24.25    , 24.333334, 24.416666, 24.5     ,\n",
       "       24.583334, 24.666666, 24.75    , 24.833334, 24.916666, 25.      ,\n",
       "       25.083334, 25.166666, 25.25    , 25.333334, 25.416666, 25.5     ,\n",
       "       25.583334, 25.666666, 25.75    , 25.833334, 25.916666, 26.      ,\n",
       "       26.083334, 26.166666, 26.25    , 26.333334, 26.416666, 26.5     ,\n",
       "       26.583334, 26.666666, 26.75    , 26.833334, 26.916666, 27.      ,\n",
       "       27.083334, 27.166666, 27.25    , 27.333334, 27.416666, 27.5     ,\n",
       "       27.583334, 27.666666, 27.75    , 27.833334, 27.916666, 28.      ,\n",
       "       28.083334, 28.166666, 28.25    , 28.333334, 28.416666, 28.5     ,\n",
       "       28.583334, 28.666666, 28.75    , 28.833334, 28.916666, 29.      ,\n",
       "       29.083334, 29.166666, 29.25    , 29.333334, 29.416666, 29.5     ,\n",
       "       29.583334, 29.666666, 29.75    , 29.833334, 29.916666, 30.      ,\n",
       "       30.083334, 30.166666, 30.25    , 30.333334, 30.416666, 30.5     ,\n",
       "       30.583334, 30.666666, 30.75    , 30.833334, 30.916666, 31.      ,\n",
       "       31.083334, 31.166666, 31.25    , 31.333334, 31.416666, 31.5     ,\n",
       "       31.583334, 31.666666, 31.75    , 31.833334, 31.916666, 32.      ,\n",
       "       32.083332, 32.166668, 32.25    , 32.333332, 32.416668, 32.5     ,\n",
       "       32.583332, 32.666668, 32.75    , 32.833332, 32.916668, 33.      ,\n",
       "       33.083332, 33.166668, 33.25    , 33.333332, 33.416668, 33.5     ,\n",
       "       33.583332, 33.666668, 33.75    , 33.833332, 33.916668, 34.      ,\n",
       "       34.083332, 34.166668, 34.25    , 34.333332, 34.416668, 34.5     ],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-20.92 -20.83 ... -6.083 -6.0</div><input id='attrs-0e0754c3-2f05-4232-b063-faf612581ea8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0e0754c3-2f05-4232-b063-faf612581ea8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b7858803-6acc-45ba-92ef-ab5b762a35e7' class='xr-var-data-in' type='checkbox'><label for='data-b7858803-6acc-45ba-92ef-ab5b762a35e7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>X</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>step :</span></dt><dd>0.0833282470703125</dd><dt><span>unit_long :</span></dt><dd>Degrees East</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>valid_max :</span></dt><dd>-6.0</dd><dt><span>valid_min :</span></dt><dd>-20.916666</dd></dl></div><div class='xr-var-data'><pre>array([-20.916666, -20.833334, -20.75    , -20.666666, -20.583334, -20.5     ,\n",
       "       -20.416666, -20.333334, -20.25    , -20.166666, -20.083334, -20.      ,\n",
       "       -19.916666, -19.833334, -19.75    , -19.666666, -19.583334, -19.5     ,\n",
       "       -19.416666, -19.333334, -19.25    , -19.166666, -19.083334, -19.      ,\n",
       "       -18.916666, -18.833334, -18.75    , -18.666666, -18.583334, -18.5     ,\n",
       "       -18.416666, -18.333334, -18.25    , -18.166666, -18.083334, -18.      ,\n",
       "       -17.916666, -17.833334, -17.75    , -17.666666, -17.583334, -17.5     ,\n",
       "       -17.416666, -17.333334, -17.25    , -17.166666, -17.083334, -17.      ,\n",
       "       -16.916666, -16.833334, -16.75    , -16.666666, -16.583334, -16.5     ,\n",
       "       -16.416666, -16.333334, -16.25    , -16.166666, -16.083334, -16.      ,\n",
       "       -15.916667, -15.833333, -15.75    , -15.666667, -15.583333, -15.5     ,\n",
       "       -15.416667, -15.333333, -15.25    , -15.166667, -15.083333, -15.      ,\n",
       "       -14.916667, -14.833333, -14.75    , -14.666667, -14.583333, -14.5     ,\n",
       "       -14.416667, -14.333333, -14.25    , -14.166667, -14.083333, -14.      ,\n",
       "       -13.916667, -13.833333, -13.75    , -13.666667, -13.583333, -13.5     ,\n",
       "       -13.416667, -13.333333, -13.25    , -13.166667, -13.083333, -13.      ,\n",
       "       -12.916667, -12.833333, -12.75    , -12.666667, -12.583333, -12.5     ,\n",
       "       -12.416667, -12.333333, -12.25    , -12.166667, -12.083333, -12.      ,\n",
       "       -11.916667, -11.833333, -11.75    , -11.666667, -11.583333, -11.5     ,\n",
       "       -11.416667, -11.333333, -11.25    , -11.166667, -11.083333, -11.      ,\n",
       "       -10.916667, -10.833333, -10.75    , -10.666667, -10.583333, -10.5     ,\n",
       "       -10.416667, -10.333333, -10.25    , -10.166667, -10.083333, -10.      ,\n",
       "        -9.916667,  -9.833333,  -9.75    ,  -9.666667,  -9.583333,  -9.5     ,\n",
       "        -9.416667,  -9.333333,  -9.25    ,  -9.166667,  -9.083333,  -9.      ,\n",
       "        -8.916667,  -8.833333,  -8.75    ,  -8.666667,  -8.583333,  -8.5     ,\n",
       "        -8.416667,  -8.333333,  -8.25    ,  -8.166667,  -8.083333,  -8.      ,\n",
       "        -7.916667,  -7.833333,  -7.75    ,  -7.666667,  -7.583333,  -7.5     ,\n",
       "        -7.416667,  -7.333333,  -7.25    ,  -7.166667,  -7.083333,  -7.      ,\n",
       "        -6.916667,  -6.833333,  -6.75    ,  -6.666667,  -6.583333,  -6.5     ,\n",
       "        -6.416667,  -6.333333,  -6.25    ,  -6.166667,  -6.083333,  -6.      ],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2014-01-01 ... 2021-01-01</div><input id='attrs-4dbc3445-8362-41c0-abee-ae9393fb6d7a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4dbc3445-8362-41c0-abee-ae9393fb6d7a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-af27d86b-a382-42e8-9c1e-a9b269394317' class='xr-var-data-in' type='checkbox'><label for='data-af27d86b-a382-42e8-9c1e-a9b269394317' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>valid_min :</span></dt><dd>561024</dd><dt><span>valid_max :</span></dt><dd>622392</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2014-01-01T00:00:00.000000000&#x27;, &#x27;2014-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-01-03T00:00:00.000000000&#x27;, ..., &#x27;2020-12-30T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-12-31T00:00:00.000000000&#x27;, &#x27;2021-01-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-518705d5-e662-499c-bc42-c969df8373d9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-518705d5-e662-499c-bc42-c969df8373d9' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>thetao</span></div><div class='xr-var-dims'>(time, depth, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a00d6bd7-6347-4710-9a1b-6307e1cf5996' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a00d6bd7-6347-4710-9a1b-6307e1cf5996' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-78bb2d64-61e8-4e25-9d92-b09af7043e18' class='xr-var-data-in' type='checkbox'><label for='data-78bb2d64-61e8-4e25-9d92-b09af7043e18' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[4061080800 values with dtype=float64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-9cd7076a-acd0-4967-9092-f1836cef1da8' class='xr-section-summary-in' type='checkbox'  ><label for='section-9cd7076a-acd0-4967-9092-f1836cef1da8' class='xr-section-summary' >Indexes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>depth</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-3509d9c1-9f32-4485-b922-59d9348913b0' class='xr-index-data-in' type='checkbox'/><label for='index-3509d9c1-9f32-4485-b922-59d9348913b0' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0.49402499198913574,  1.5413750410079956,  2.6456689834594727,\n",
       "        3.8194949626922607,   5.078224182128906,   6.440614223480225,\n",
       "          7.92956018447876,   9.572997093200684,  11.404999732971191,\n",
       "        13.467140197753906,  15.810070037841797,  18.495559692382812,\n",
       "        21.598819732666016,  25.211410522460938,  29.444730758666992,\n",
       "         34.43415069580078,  40.344051361083984,   47.37369155883789,\n",
       "         55.76428985595703,   65.80726623535156,   77.85385131835938,\n",
       "          92.3260726928711,  109.72930145263672,  130.66600036621094,\n",
       "        155.85069274902344,  186.12559509277344,  222.47520446777344,\n",
       "         266.0403137207031,   318.1274108886719,   380.2130126953125,\n",
       "         453.9377136230469,   541.0889282226562,   643.5667724609375,\n",
       "         763.3331298828125,   902.3392944335938,    1062.43994140625,\n",
       "            1245.291015625,     1452.2509765625,  1684.2840576171875,\n",
       "        1941.8929443359375,   2225.077880859375,        2533.3359375,\n",
       "         2865.702880859375,   3220.820068359375,   3597.031982421875,\n",
       "          3992.48388671875,    4405.22412109375,      4833.291015625,\n",
       "           5274.7841796875],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;depth&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-a555281c-677e-45dc-b77a-54b929c22ee0' class='xr-index-data-in' type='checkbox'/><label for='index-a555281c-677e-45dc-b77a-54b929c22ee0' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([19.58333396911621, 19.66666603088379,             19.75,\n",
       "       19.83333396911621, 19.91666603088379,              20.0,\n",
       "       20.08333396911621, 20.16666603088379,             20.25,\n",
       "       20.33333396911621,\n",
       "       ...\n",
       "                   33.75, 33.83333206176758, 33.91666793823242,\n",
       "                    34.0, 34.08333206176758, 34.16666793823242,\n",
       "                   34.25, 34.33333206176758, 34.41666793823242,\n",
       "                    34.5],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;latitude&#x27;, length=180))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-7723fa2a-7673-4d5a-9b89-92da5a6a63b9' class='xr-index-data-in' type='checkbox'/><label for='index-7723fa2a-7673-4d5a-9b89-92da5a6a63b9' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-20.91666603088379, -20.83333396911621,             -20.75,\n",
       "       -20.66666603088379, -20.58333396911621,              -20.5,\n",
       "       -20.41666603088379, -20.33333396911621,             -20.25,\n",
       "       -20.16666603088379,\n",
       "       ...\n",
       "                    -6.75, -6.666666507720947, -6.583333492279053,\n",
       "                     -6.5, -6.416666507720947, -6.333333492279053,\n",
       "                    -6.25, -6.166666507720947, -6.083333492279053,\n",
       "                     -6.0],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;longitude&#x27;, length=180))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-e76037b7-fac7-4d45-9d08-8eecf9138a9f' class='xr-index-data-in' type='checkbox'/><label for='index-e76037b7-fac7-4d45-9d08-8eecf9138a9f' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2014-01-01&#x27;, &#x27;2014-01-02&#x27;, &#x27;2014-01-03&#x27;, &#x27;2014-01-04&#x27;,\n",
       "               &#x27;2014-01-05&#x27;, &#x27;2014-01-06&#x27;, &#x27;2014-01-07&#x27;, &#x27;2014-01-08&#x27;,\n",
       "               &#x27;2014-01-09&#x27;, &#x27;2014-01-10&#x27;,\n",
       "               ...\n",
       "               &#x27;2020-12-23&#x27;, &#x27;2020-12-24&#x27;, &#x27;2020-12-25&#x27;, &#x27;2020-12-26&#x27;,\n",
       "               &#x27;2020-12-27&#x27;, &#x27;2020-12-28&#x27;, &#x27;2020-12-29&#x27;, &#x27;2020-12-30&#x27;,\n",
       "               &#x27;2020-12-31&#x27;, &#x27;2021-01-01&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=2558, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-00a92864-2ec8-402a-a760-684eed597677' class='xr-section-summary-in' type='checkbox'  ><label for='section-00a92864-2ec8-402a-a760-684eed597677' class='xr-section-summary' >Attributes: <span>(25)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.4</dd><dt><span>bulletin_date :</span></dt><dd>2021-07-07 00:00:00</dd><dt><span>bulletin_type :</span></dt><dd>operational</dd><dt><span>comment :</span></dt><dd>CMEMS product</dd><dt><span>domain_name :</span></dt><dd>GL12</dd><dt><span>easting :</span></dt><dd>longitude</dd><dt><span>field_date :</span></dt><dd>2021-06-30 00:00:00</dd><dt><span>field_julian_date :</span></dt><dd>26113.0</dd><dt><span>field_type :</span></dt><dd>mean</dd><dt><span>forecast_range :</span></dt><dd></dd><dt><span>forecast_type :</span></dt><dd></dd><dt><span>history :</span></dt><dd>2023/06/01 16:20:05 MERCATOR OCEAN Netcdf creation</dd><dt><span>institution :</span></dt><dd>MERCATOR OCEAN</dd><dt><span>julian_day_unit :</span></dt><dd>days since 1950-01-01 00:00:00</dd><dt><span>latitude_max :</span></dt><dd>90.0</dd><dt><span>latitude_min :</span></dt><dd>-80.0</dd><dt><span>longitude_max :</span></dt><dd>179.9166717529297</dd><dt><span>longitude_min :</span></dt><dd>-180.0</dd><dt><span>northing :</span></dt><dd>latitude</dd><dt><span>references :</span></dt><dd>http://www.mercator-ocean.fr</dd><dt><span>source :</span></dt><dd>MERCATOR GLORYS12V1</dd><dt><span>title :</span></dt><dd>daily mean fields from Global Ocean Physics Analysis and Forecast updated Daily</dd><dt><span>z_max :</span></dt><dd>5727.9169921875</dd><dt><span>z_min :</span></dt><dd>0.49402499198913574</dd><dt><span>copernicusmarine_version :</span></dt><dd>1.3.3</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 32GB\n",
       "Dimensions:    (depth: 49, latitude: 180, longitude: 180, time: 2558)\n",
       "Coordinates:\n",
       "  * depth      (depth) float32 196B 0.494 1.541 2.646 ... 4.833e+03 5.275e+03\n",
       "  * latitude   (latitude) float32 720B 19.58 19.67 19.75 ... 34.33 34.42 34.5\n",
       "  * longitude  (longitude) float32 720B -20.92 -20.83 -20.75 ... -6.083 -6.0\n",
       "  * time       (time) datetime64[ns] 20kB 2014-01-01 2014-01-02 ... 2021-01-01\n",
       "Data variables:\n",
       "    thetao     (time, depth, latitude, longitude) float64 32GB ...\n",
       "Attributes: (12/25)\n",
       "    Conventions:               CF-1.4\n",
       "    bulletin_date:             2021-07-07 00:00:00\n",
       "    bulletin_type:             operational\n",
       "    comment:                   CMEMS product\n",
       "    domain_name:               GL12\n",
       "    easting:                   longitude\n",
       "    ...                        ...\n",
       "    references:                http://www.mercator-ocean.fr\n",
       "    source:                    MERCATOR GLORYS12V1\n",
       "    title:                     daily mean fields from Global Ocean Physics An...\n",
       "    z_max:                     5727.9169921875\n",
       "    z_min:                     0.49402499198913574\n",
       "    copernicusmarine_version:  1.3.3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "from aurora import Aurora, Batch, Metadata, normalisation, rollout\n",
    "\n",
    "\n",
    "\n",
    "#dataset = xr.open_dataset(\"/Users/victormedina/Desktop/cmems_preprocessed_oceanographic_data.nc\", engine=\"netcdf4\")\n",
    "#dataset = xr.open_dataset(\"D://Aaron///cmems_mod_glo_phy_my_0.083deg_P1D-m_v1_little.nc\")\n",
    "#dataset = xr.open_dataset(\"D://Aaron//cmems_mod_glo_phy_my_0.083deg_P1D-m.nc\").isel(time=slice(0,30))\n",
    "#dataset = xr.open_dataset(\"D://Aaron//cmems_mod_glo_phy_my_0.083deg_P1D-m_6years_thetao_v3.nc\")\n",
    "dataset = xr.open_dataset(\"C://Users//Public//Downloads//Datos//cmems_mod_glo_phy_my_0.083deg_P1D-m_6years_thetao_v3.nc\")\n",
    "#dataset = xr.open_dataset(\"/Users/victormedina/Desktop/TFG/Datos/cmems_mod_glo_phy_my_0.083deg_P1D-m_v1.nc\", engine=\"netcdf4\") #dataset de 3 dias\n",
    "#dataset = xr.open_dataset(\"/Users/victormedina/Desktop/TFG/Datos/cmems_mod_glo_phy_my_0.083deg_P1D-m.nc\", engine=\"netcdf4\") #dataset de 3 años que solo ejecuta en pc grande\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar variable \n",
    "lsm=xr.open_dataset(\"C://Users//Public//Downloads//Datos//datos_mascara.nc\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variables = ['thetao']  # Solo 'thetao'\n",
    "dataset = dataset[variables]\n",
    "\n",
    "# Cargar el dataset solo con la variable que necesitas\n",
    "variables = ['thetao']  # Selecciona solo 'thetao'\n",
    "\n",
    "\n",
    "# Filtrar por la profundidad (limitando el número de niveles de profundidad)\n",
    "dataset = dataset.isel(depth=slice(0, 10))  # Limitar a los primeros 10 niveles de profundidad\n",
    "ocean_levels = dataset['depth'].values\n",
    "\n",
    "# Ajustar las longitudes para que coincidan en rango (de -180 a 180) y latitudes para interpolación\n",
    "lsm_copy = lsm.copy()\n",
    "lsm_copy = lsm_copy.assign_coords(longitude=(((lsm_copy.longitude + 180) % 360) - 180))\n",
    "\n",
    "# Interpolar la variable lsm para que coincida con la resolución del dataset\n",
    "lsm_interp = lsm_copy.interp(latitude=dataset.latitude, longitude=dataset.longitude, method=\"nearest\")\n",
    "\n",
    "# Asignar la variable lsm al dataset sin añadir coordenadas innecesarias\n",
    "lsm_interp_clean = lsm_interp.fillna(0)  # Reemplazar los NaNs por ceros\n",
    "dataset['lsm'] = lsm_interp_clean['lsm']\n",
    "\n",
    "# Eliminar las coordenadas innecesarias si se añadieron automáticamente\n",
    "coordinates_to_drop = ['number', 'step', 'surface', 'valid_time']\n",
    "for coord in coordinates_to_drop:\n",
    "    if coord in dataset.coords:\n",
    "        dataset = dataset.drop_vars(coord)\n",
    "\n",
    "# Verificar y ajustar las latitudes para asegurar que están en el orden correcto y dentro del rango adecuado\n",
    "def check_latitudes(dataset: xr.Dataset) -> xr.Dataset:\n",
    "    latitude = dataset['latitude'].values\n",
    "    if not (np.all(latitude <= 90) and np.all(latitude >= -90)):\n",
    "        raise ValueError(\"Algunos valores de latitud están fuera del rango [-90, 90]. Por favor, corrígelos.\")\n",
    "    if not np.all(np.diff(latitude) < 0):\n",
    "        dataset = dataset.sortby('latitude', ascending=False)\n",
    "    return dataset\n",
    "\n",
    "# Ajustar las longitudes para que estén dentro del rango [0,360]\n",
    "def check_longitudes(dataset: xr.Dataset) -> xr.Dataset:\n",
    "    dataset = dataset.assign_coords(longitude=((dataset.longitude + 360) % 360))\n",
    "    return dataset\n",
    "\n",
    "# Aplicar funciones de verificación al dataset\n",
    "dataset = check_latitudes(dataset)\n",
    "dataset = check_longitudes(dataset)\n",
    "\n",
    "# Convertir latitudes y longitudes a tensores de Torch para su posterior uso\n",
    "latitude = torch.from_numpy(dataset['latitude'].values).float()\n",
    "longitude = torch.from_numpy(dataset['longitude'].values).float()\n",
    "\n",
    "# Revisar si hay valores NaN restantes después de la interpolación y eliminarlos si es necesario\n",
    "dataset = dataset.dropna(dim=\"latitude\", how=\"all\").dropna(dim=\"longitude\", how=\"all\")\n",
    "\n",
    "# Rellenar los valores NaN con la media de la variable\n",
    "def fill_nan_with_mean(var: xr.DataArray) -> xr.DataArray:\n",
    "    if var.isnull().any():\n",
    "        return var.fillna(var.mean())\n",
    "    else:\n",
    "        return var\n",
    "\n",
    "for var in variables:\n",
    "    dataset[var] = fill_nan_with_mean(dataset[var])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir funciones para cargar datos\n",
    "def load_ocean_surface(v: str, sample_sets: list) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Carga los datos de variables de superficie para un conjunto de muestras.\n",
    "\n",
    "    Args:\n",
    "        v (str): Nombre de la variable.\n",
    "        sample_sets (list): Lista de conjuntos de datos de muestra.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Datos y targets concatenados de la variable de superficie.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    target_list = []\n",
    "    for sample_set in sample_sets:\n",
    "        sel_dict = {}\n",
    "        if 'depth' in sample_set[v].dims:\n",
    "            sel_dict['depth'] = 0  # Seleccionar nivel superficial\n",
    "        data = sample_set[v].isel(**sel_dict).isel(time=slice(0, 2)).values  # (time, lat, lon)\n",
    "        data_tensor = torch.from_numpy(data).float()  # (time, lat, lon)\n",
    "        data_list.append(data_tensor)\n",
    "\n",
    "        target = sample_set[v].isel(**sel_dict).isel(time=slice(2,None)).values  # (lat, lon)\n",
    "        target_tensor = torch.from_numpy(target).float()  # (lat, lon)\n",
    "\n",
    "\n",
    "        target_list.append(target_tensor)\n",
    "\n",
    "    # Concatenar los datos a lo largo de la dimensión batch (nueva dimensión 0)\n",
    "    data_batch = torch.stack(data_list, dim=0)    # (batch_size, time, lat, lon)\n",
    "    target_batch = torch.stack(target_list, dim=0)  # (batch_size, 1, lat, lon)\n",
    "\n",
    "    return data_batch, target_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_ocean_atmos(v: str, sample_sets: list) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Carga los datos de variables atmosféricas para un conjunto de muestras.\n",
    "\n",
    "    Args:\n",
    "        v (str): Nombre de la variable.\n",
    "        sample_sets (list): Lista de conjuntos de datos de muestra.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Datos y targets concatenados de la variable atmosférica.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    target_list = []\n",
    "    for sample_set in sample_sets:\n",
    "        sel_dict = {'depth': slice(0, 10)}  # Seleccionar los primeros N niveles de profundidad\n",
    "        data = sample_set[v].isel(**sel_dict).isel(time=slice(0, 2)).values  # (time, depth, lat, lon)\n",
    "        data_tensor = torch.from_numpy(data).float()  # (time, depth, lat, lon)\n",
    "        data_list.append(data_tensor)\n",
    "\n",
    "        target = sample_set[v].isel(**sel_dict).isel(time=slice(2,None)).values  # (depth, lat, lon)\n",
    "        target_tensor = torch.from_numpy(target).float()  # (depth, lat, lon)\n",
    "        target_list.append(target_tensor)\n",
    "\n",
    "    # Concatenar los datos a lo largo de la dimensión batch\n",
    "    data_batch = torch.stack(data_list, dim=0)  # (batch_size, time, depth, lat, lon)\n",
    "    target_batch = torch.stack(target_list, dim=0)  # (batch_size, depth, lat, lon)\n",
    "\n",
    "    return data_batch, target_batch\n",
    "\n",
    "\n",
    "\n",
    "def load_static_var(v: str, sample_sets: list) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Carga una variable estática del dataset.\n",
    "\n",
    "    Args:\n",
    "        v (str): Nombre de la variable.\n",
    "        sample_sets (list): Lista de conjuntos de datos de muestra.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor con los datos de la variable estática (lat, lon).\n",
    "    \"\"\"\n",
    "    # Since static variables are the same across the batch, we can take from the first sample\n",
    "    sample_set = sample_sets[0]\n",
    "    data_var = sample_set[v]\n",
    "    dims_to_drop = [dim for dim in data_var.dims if dim not in ('latitude', 'longitude')]\n",
    "    data_var = data_var.isel({dim: 0 for dim in dims_to_drop})\n",
    "    data = data_var.values  # Should be (lat, lon)\n",
    "    data_tensor = torch.from_numpy(data).float()\n",
    "\n",
    "    return data_tensor  # Shape: (lat, lon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Aurora cargado y ajustado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "surf_vars: tuple[str, ...] = ('thetao',)\n",
    "static_vars: tuple[str, ...] = ('lsm',)\n",
    "atmos_vars: tuple[str, ...] = ('thetao',)\n",
    "\n",
    "# Crear el modelo Aurora y moverlo al dispositivo\n",
    "model = Aurora(surf_vars=surf_vars, static_vars=static_vars, atmos_vars=atmos_vars, use_lora=False,autocast=True).to(device)\n",
    "model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\", strict=False)\n",
    "print(\"Modelo Aurora cargado y ajustado exitosamente.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir el conjunto de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango de tiempo del conjunto de entrenamiento: 2014-01-01T00:00:00.000000000 a 2021-01-01T00:00:00.000000000\n",
      "Conjunto de entrenamiento: 1790 instancias temporales\n",
      "Conjunto de validación: 383 instancias temporales\n",
      "Conjunto de prueba: 385 instancias temporales\n",
      "Rango de tiempo del conjunto de entrenamiento: 2014-01-01T00:00:00.000000000 a 2018-11-25T00:00:00.000000000\n",
      "Rango de tiempo del conjunto de validación: 2018-11-26T00:00:00.000000000 a 2019-12-13T00:00:00.000000000\n",
      "Rango de tiempo del conjunto de prueba: 2019-12-14T00:00:00.000000000 a 2021-01-01T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "#de cuando a cuando es el dataset\n",
    "print(f\"Rango de tiempo del conjunto de entrenamiento: {dataset['time'].values[0]} a {dataset['time'].values[-1]}\")\n",
    "\n",
    "#Definir las estaciones del año según el mes (ya es un número entero)\n",
    "# Definir las estaciones del año según el mes\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "# Aplicar la función get_season a la columna de meses del dataset usando dask\n",
    "dataset['season'] = xr.apply_ufunc(\n",
    "    np.vectorize(get_season),\n",
    "    dataset['time'].dt.month,  # Usamos el mes directamente\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",  # Habilitar dask para procesamiento en paralelo\n",
    "    output_dtypes=[str]  # Definir el tipo de salida\n",
    ")\n",
    "#Función para dividir el dataset respetando las estaciones y evitando solapamientos\n",
    "def split_by_time(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Divide el dataset en entrenamiento, validación y prueba asegurando que todas las estaciones estén\n",
    "    representadas en cada conjunto y no haya solapamientos temporales.\n",
    "\n",
    "    Args:\n",
    "        dataset_años (xr.Dataset): El dataset con la dimensión 'time'.\n",
    "        train_ratio (float): Proporción de datos para el conjunto de entrenamiento.\n",
    "        val_ratio (float): Proporción de datos para el conjunto de validación.\n",
    "        test_ratio (float): Proporción de datos para el conjunto de prueba.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset_años (xr.Dataset): Conjunto de entrenamiento con todas las estaciones.\n",
    "        val_dataset_años (xr.Dataset): Conjunto de validación con todas las estaciones.\n",
    "        test_dataset_años (xr.Dataset): Conjunto de prueba con todas las estaciones.\n",
    "    \"\"\"\n",
    "    # Total de puntos temporales en el dataset\n",
    "    num_times = len(dataset['time'])\n",
    "    \n",
    "    # Calcular los índices para dividir los datos\n",
    "    train_index = int(train_ratio * num_times)\n",
    "    val_index = int(val_ratio * num_times)\n",
    "    \n",
    "    # Crear los conjuntos secuencialmente por tiempo (sin solapamiento)\n",
    "    train_dataset = dataset.isel(time=slice(0, train_index))\n",
    "    val_dataset = dataset.isel(time=slice(train_index, train_index + val_index))\n",
    "    test_dataset = dataset.isel(time=slice(train_index + val_index, num_times))\n",
    "\n",
    "    # Ahora aseguramos que cada conjunto tenga ejemplos de todas las estaciones\n",
    "    def ensure_all_seasons(dataset):\n",
    "        # Verificar qué estaciones están presentes en este dataset\n",
    "        seasons_present = np.unique(dataset['season'].values)\n",
    "        missing_seasons = set(['winter', 'spring', 'summer', 'fall']) - set(seasons_present)\n",
    "        \n",
    "        if missing_seasons:\n",
    "            raise ValueError(f\"El dataset no tiene datos de las estaciones: {missing_seasons}\")\n",
    "        return dataset\n",
    "    \n",
    "    train_dataset = ensure_all_seasons(train_dataset)\n",
    "    val_dataset = ensure_all_seasons(val_dataset)\n",
    "    test_dataset = ensure_all_seasons(test_dataset)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Llamar a la función para dividir el dataset secuencialmente y asegurar que contenga todas las estaciones\n",
    "train_dataset, val_dataset, test_dataset = split_by_time(dataset)\n",
    "#Imprimir tamaños y rangos de los conjuntos de datos resultantes\n",
    "print(f\"Conjunto de entrenamiento: {len(train_dataset['time'])} instancias temporales\")\n",
    "print(f\"Conjunto de validación: {len(val_dataset['time'])} instancias temporales\")\n",
    "print(f\"Conjunto de prueba: {len(test_dataset['time'])} instancias temporales\")\n",
    "\n",
    "print(f\"Rango de tiempo del conjunto de entrenamiento: {train_dataset['time'].values[0]} a {train_dataset['time'].values[-1]}\")\n",
    "print(f\"Rango de tiempo del conjunto de validación: {val_dataset['time'].values[0]} a {val_dataset['time'].values[-1]}\")\n",
    "print(f\"Rango de tiempo del conjunto de prueba: {test_dataset['time'].values[0]} a {test_dataset['time'].values[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable  thetao  actualizadas exitosamente con el conjunto de entrenamiento.\n"
     ]
    }
   ],
   "source": [
    "train_ocean_levels = train_dataset['depth'].values\n",
    "\n",
    "# Normalización para thetao en los niveles oceánicos\n",
    "for level in train_ocean_levels:\n",
    "    level_str = f\"{level}\"\n",
    "    var = \"thetao\"\n",
    "    data = train_dataset[var].sel(depth=level).values\n",
    "    mean = np.nanmean(data)\n",
    "    std = np.nanstd(data)\n",
    "    normalisation.locations[f\"{var}_{level_str}\"] = mean\n",
    "    normalisation.scales[f\"{var}_{level_str}\"] = std\n",
    "\n",
    "# Normalización para thetao en la superficie\n",
    "surface_vars = [\"thetao\"]\n",
    "for var in surface_vars:\n",
    "    if 'depth' in train_dataset[var].dims:\n",
    "        data = train_dataset[var].isel(depth=0).values\n",
    "    else:\n",
    "        data = train_dataset[var].values\n",
    "    mean = np.nanmean(data)\n",
    "    std = np.nanstd(data)\n",
    "    normalisation.locations[var] = mean\n",
    "    normalisation.scales[var] = std\n",
    "\n",
    "print(\"Variable  thetao  actualizadas exitosamente con el conjunto de entrenamiento.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, dataset: xr.Dataset, sample_size: int, batch_size: int, shuffle: bool = True, padding: bool = True):\n",
    "        \"\"\"\n",
    "        Inicializa el BatchGenerator.\n",
    "\n",
    "        Args:\n",
    "            dataset (xr.Dataset): El conjunto de datos.\n",
    "            sample_size (int): Tamaño de cada ventana deslizante.\n",
    "            batch_size (int): Tamaño de cada batch.\n",
    "            shuffle (bool): Si se deben barajar las muestras.\n",
    "            padding (bool): Si se debe aplicar padding al último batch.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.sample_size = sample_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.padding = padding\n",
    "        self.samples = self.generate_sliding_windows()\n",
    "        if self.shuffle:\n",
    "            self.samples = self.shuffle_samples()\n",
    "\n",
    "    def generate_sliding_windows(self):\n",
    "        \"\"\"\n",
    "        Genera ventanas deslizantes sobre el eje temporal del dataset.\n",
    "\n",
    "        Returns:\n",
    "            list: Lista de muestras generadas mediante ventanas deslizantes.\n",
    "        \"\"\"\n",
    "        window_size = self.sample_size\n",
    "        windows = [slice(i, i + window_size) for i in range(0, len(self.dataset.time) - window_size + 1)]\n",
    "        samples = [self.dataset.isel(time=w) for w in windows]\n",
    "        return samples\n",
    "\n",
    "    def shuffle_samples(self):\n",
    "        \"\"\"\n",
    "        Baraja las muestras generadas.\n",
    "\n",
    "        Returns:\n",
    "            list: Lista de muestras barajadas.\n",
    "        \"\"\"\n",
    "        samples_copy = self.samples.copy()\n",
    "        np.random.shuffle(samples_copy)\n",
    "        return samples_copy\n",
    "\n",
    "    def load_ocean_batch(self, sample_sets):\n",
    "        \"\"\"\n",
    "    Carga un batch de datos a partir de un conjunto de muestras.\n",
    "\n",
    "    Args:\n",
    "        sample_sets (list): Lista de conjuntos de datos de muestra.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Batch, Batch]: Batch de datos y batch de targets.\n",
    "        \"\"\"\n",
    "        is_padding = any(sample.attrs.get('is_padding', False) for sample in sample_sets)\n",
    "\n",
    "    # Llamar a las funciones de carga modificadas\n",
    "        surf_data, surf_target = load_ocean_surface(\"thetao\", sample_sets)\n",
    "        atmos_data, atmos_target = load_ocean_atmos(\"thetao\", sample_sets)\n",
    "        static_data = load_static_var(\"lsm\", sample_sets).to(device)\n",
    "\n",
    "        times = [\n",
    "            sample_set['time'].values[-1].astype('datetime64[s]').astype(datetime)\n",
    "            for sample_set in sample_sets\n",
    "        ]\n",
    "    # Crear instancia de Batch para el batch completo\n",
    "        batch = Batch(\n",
    "            surf_vars={\n",
    "                \"thetao\": surf_data,\n",
    "            },\n",
    "            static_vars={\n",
    "                \"lsm\": static_data,\n",
    "            },\n",
    "            atmos_vars={\n",
    "                \"thetao\": atmos_data,\n",
    "            },\n",
    "            metadata=Metadata(\n",
    "                lat=latitude,\n",
    "                lon=longitude,\n",
    "                time=times,\n",
    "                atmos_levels=ocean_levels,\n",
    "            )\n",
    "        )\n",
    "        batch.metadata.is_padding = is_padding\n",
    "\n",
    "        batch_target = Batch(\n",
    "            surf_vars={\n",
    "                \"thetao\": surf_target,\n",
    "            },\n",
    "            static_vars={\n",
    "             \"lsm\": static_data,  # Asumimos que los static_vars son iguales para data y target\n",
    "            },\n",
    "            atmos_vars={\n",
    "                \"thetao\": atmos_target,\n",
    "            },\n",
    "            metadata=Metadata(\n",
    "                lat=latitude,\n",
    "                lon=longitude,\n",
    "                time=times,\n",
    "                atmos_levels=ocean_levels,\n",
    "            )\n",
    "        )\n",
    "        batch_target.metadata.is_padding = is_padding\n",
    "\n",
    "        return batch, batch_target\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterador que genera batches de datos.\n",
    "\n",
    "        Yields:\n",
    "            Tuple[list, list]: Batch de datos y batch de targets.\n",
    "        \"\"\"\n",
    "        # Dividimos las muestras en batches\n",
    "        for i in range(0, len(self.samples), self.batch_size):\n",
    "            batch_samples = self.samples[i:i + self.batch_size]\n",
    "\n",
    "            # Aplicamos padding si es necesario\n",
    "            if len(batch_samples) < self.batch_size and self.padding:\n",
    "                num_padding = self.batch_size - len(batch_samples)\n",
    "                for _ in range(num_padding):\n",
    "                    sample = self.samples[i % len(self.samples)]\n",
    "                    sample = sample.copy()\n",
    "                    sample.attrs['is_padding'] = True\n",
    "                    batch_samples.append(sample)\n",
    "\n",
    "            batch, batch_target = self.load_ocean_batch(batch_samples)\n",
    "            yield batch, batch_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función RMSE para la validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions: np.ndarray, targets: np.ndarray, latitudes: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el error cuadrático medio (RMSE) para las predicciones y los targets.\n",
    "\n",
    "    Args:\n",
    "        predictions (np.ndarray): Predicciones del modelo.\n",
    "        targets (np.ndarray): Targets reales.\n",
    "        latitudes (np.ndarray): Latitudes de las predicciones y los targets.\n",
    "\n",
    "    Returns:\n",
    "        float: El RMSE calculado.\n",
    "    \"\"\"\n",
    "    # Convertir latitudes a radianes y calcular los pesos\n",
    "    lat_rad = np.deg2rad(latitudes)\n",
    "    weights = np.cos(lat_rad)\n",
    "\n",
    "    # Normalizar los pesos para que su promedio sea 1\n",
    "    weights_mean = np.mean(weights)\n",
    "    weights_normalized = weights / weights_mean\n",
    "\n",
    "    # Agregar dimensiones para el broadcasting\n",
    "    weights_normalized = weights_normalized[np.newaxis, :, np.newaxis]\n",
    "\n",
    "    # Calcular los errores cuadrados\n",
    "    squared_errors = (predictions - targets) ** 2\n",
    "\n",
    "    # Multiplicar por los pesos normalizados\n",
    "    weighted_squared_errors = squared_errors * weights_normalized\n",
    "\n",
    "    # Calcular el numerador: suma de los errores cuadrados ponderados\n",
    "    numerator = np.sum(weighted_squared_errors)\n",
    "\n",
    "    # Calcular el denominador: suma de los pesos\n",
    "    denominator = predictions.shape[0] * predictions.shape[1] * predictions.shape[2]\n",
    "\n",
    "    # Calcular el RMSE ponderado\n",
    "    rmse_weighted = np.sqrt(numerator / denominator)\n",
    "\n",
    "    return rmse_weighted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Función de entrenamiento con eval comentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, \n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    batch_size, \n",
    "    num_epochs, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    sample_size, \n",
    "    device, \n",
    "    latitudes,\n",
    "):\n",
    "    \"\"\"\n",
    "    Entrena el modelo y calcula el RMSE en la validación.\n",
    "    \"\"\"\n",
    "    # Generadores de batches para entrenamiento y validación\n",
    "    train_generator = BatchGenerator(train_dataset, sample_size, batch_size, shuffle=True, padding=True)\n",
    "    val_generator = BatchGenerator(val_dataset, sample_size, batch_size, shuffle=False, padding=False)\n",
    "\n",
    "    # Listas para almacenar pérdidas y RMSE\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_rmses = []\n",
    "\n",
    "    # Inicializar el escalador para AMP\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for batch, batch_target in tqdm(train_generator, desc=f\"Epoch {epoch + 1}/{num_epochs} - Train\"): \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if getattr(batch.metadata, 'is_padding', False):\n",
    "                continue\n",
    "\n",
    "            # Obtener el target y moverlo al dispositivo\n",
    "            target = batch_target.surf_vars['thetao'].to(device)  # Shape: (batch_size, 1, lat, lon)\n",
    "\n",
    "            with autocast(device_type=device.type):\n",
    "                # Obtener las predicciones del modelo\n",
    "                outputs = [out.to(device) for out in rollout(model, batch, steps=1)]\n",
    "                model_output = outputs[0]\n",
    "                output_tensor = model_output.surf_vars['thetao']  # Shape: (batch_size, 1, lat, lon)\n",
    "\n",
    "                # Calcular la pérdida sin reducción\n",
    "                loss_matrix = criterion(output_tensor, target)  # Shape: (batch_size, 1, lat, lon)\n",
    "\n",
    "                # Promediar en latitud y longitud para obtener la pérdida por muestra\n",
    "                loss_per_sample = loss_matrix.mean(dim=[2, 3])  # Shape: (batch_size, 1)\n",
    "                loss_per_sample = loss_per_sample.squeeze(1)     # Shape: (batch_size,)\n",
    "\n",
    "                # Calcular la pérdida total del batch\n",
    "                loss = loss_per_sample.mean()\n",
    "\n",
    "            # Backpropagación\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Acumular la pérdida\n",
    "            train_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        # Promediar la pérdida del entrenamiento\n",
    "        if total_batches > 0:\n",
    "            average_train_loss = train_loss / total_batches\n",
    "            train_losses.append(average_train_loss)\n",
    "        else:\n",
    "            train_losses.append(0)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.6f}\")\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_val_batches = 0\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch, batch_target in tqdm(val_generator, desc=f\"Epoch {epoch + 1}/{num_epochs} - Validation\"):\n",
    "                if getattr(batch.metadata, 'is_padding', False):\n",
    "                    continue\n",
    "\n",
    "                target = batch_target.surf_vars['thetao'].to(device)\n",
    "\n",
    "                outputs = [out.to(device) for out in rollout(model, batch, steps=1)]\n",
    "                model_output = outputs[0]\n",
    "                output_tensor = model_output.surf_vars['thetao']\n",
    "\n",
    "                # Calcular la pérdida sin reducción\n",
    "                loss_matrix = criterion(output_tensor, target)  # Shape: (batch_size, 1, lat, lon)\n",
    "\n",
    "                # Promediar en latitud y longitud para obtener la pérdida por muestra\n",
    "                loss_per_sample = loss_matrix.mean(dim=[2, 3])  # Shape: (batch_size, 1)\n",
    "                loss_per_sample = loss_per_sample.squeeze(1)     # Shape: (batch_size,)\n",
    "\n",
    "                # Calcular la pérdida total del batch\n",
    "                loss = loss_per_sample.mean()\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                total_val_batches += 1\n",
    "\n",
    "                # Recopilar predicciones y targets para calcular el RMSE\n",
    "                val_predictions.append(output_tensor.detach().cpu().numpy())\n",
    "                val_targets.append(target.detach().cpu().numpy())\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "        # Promediar la pérdida de validación\n",
    "        if total_val_batches > 0:\n",
    "            average_val_loss = val_loss / total_val_batches\n",
    "            val_losses.append(average_val_loss)\n",
    "        else:\n",
    "            val_losses.append(0)\n",
    "        \n",
    "        # Calcular el RMSE sobre el conjunto de validación\n",
    "        if val_predictions and val_targets:\n",
    "            val_predictions = np.concatenate(val_predictions, axis=0)  # Shape: (num_samples, 1, lat, lon)\n",
    "            val_targets = np.concatenate(val_targets, axis=0)          # Shape: (num_samples, 1, lat, lon)\n",
    "\n",
    "            # Eliminar la dimensión singleton\n",
    "            val_predictions = val_predictions.squeeze(axis=1)  # Shape: (num_samples, lat, lon)\n",
    "            val_targets = val_targets.squeeze(axis=1)          # Shape: (num_samples, lat, lon)\n",
    "\n",
    "            # Calcular el RMSE\n",
    "            val_rmse = rmse(val_predictions, val_targets, latitudes)\n",
    "            val_rmses.append(val_rmse)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_losses[-1]:.6f}, Validation RMSE: {val_rmse:.6f}\")\n",
    "        else:\n",
    "            val_rmses.append(0)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_losses[-1]:.6f}, No se pudo calcular el RMSE.\")\n",
    "\n",
    "    return train_losses, val_losses, val_rmses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 2: congelamos todos los parámetros del modelo excepto los del decodificador y ajustamos el learning rate a 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Train: 224it [08:48,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.354691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Validation: 48it [03:40,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Validation Loss: 0.198365, Validation RMSE: 0.284481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.183708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Validation: 48it [03:38,  4.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Validation Loss: 0.158869, Validation RMSE: 0.222828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Train: 224it [06:31,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.159673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Validation: 48it [03:35,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Validation Loss: 0.145079, Validation RMSE: 0.197405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.148059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Validation Loss: 0.138017, Validation RMSE: 0.183352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.140948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Validation Loss: 0.131248, Validation RMSE: 0.172616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.136244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - Validation: 48it [03:34,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Validation Loss: 0.125506, Validation RMSE: 0.164256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.132888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Validation: 48it [03:33,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Validation Loss: 0.121701, Validation RMSE: 0.158443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.130393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - Validation: 48it [03:36,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Validation Loss: 0.118269, Validation RMSE: 0.153521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.128464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Validation Loss: 0.115630, Validation RMSE: 0.149660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.126948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Validation: 48it [03:33,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Validation Loss: 0.113220, Validation RMSE: 0.146309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.125688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - Validation: 48it [03:34,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Validation Loss: 0.111840, Validation RMSE: 0.144056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.124661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Validation: 48it [03:34,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Validation Loss: 0.110381, Validation RMSE: 0.141909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.123785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Validation Loss: 0.109019, Validation RMSE: 0.139961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.123042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Validation Loss: 0.108388, Validation RMSE: 0.138776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.122406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 - Validation: 48it [03:33,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Validation Loss: 0.107188, Validation RMSE: 0.137169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.121834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Validation Loss: 0.106962, Validation RMSE: 0.136506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.121374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Validation Loss: 0.106215, Validation RMSE: 0.135412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.120911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Validation Loss: 0.105732, Validation RMSE: 0.134612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - Train: 224it [06:31,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.120449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Validation Loss: 0.105039, Validation RMSE: 0.133647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.120185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Validation Loss: 0.104775, Validation RMSE: 0.133127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.119847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - Validation: 48it [03:34,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Validation Loss: 0.104332, Validation RMSE: 0.132466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - Train: 224it [06:34,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.119574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - Validation: 48it [03:34,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Validation Loss: 0.104160, Validation RMSE: 0.132056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.119307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 - Validation: 48it [03:33,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Validation Loss: 0.103715, Validation RMSE: 0.131448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.119062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 - Validation: 48it [03:33,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Validation Loss: 0.103537, Validation RMSE: 0.131082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.118846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 - Validation: 48it [03:33,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Validation Loss: 0.103253, Validation RMSE: 0.130652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.118658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - Validation: 48it [03:33,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Validation Loss: 0.103230, Validation RMSE: 0.130473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 - Train: 224it [06:30,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.118462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 - Validation: 48it [03:33,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Validation Loss: 0.102932, Validation RMSE: 0.130030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.118215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 - Validation: 48it [03:33,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Validation Loss: 0.102718, Validation RMSE: 0.129710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 - Train: 224it [06:29,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.118125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 - Validation: 48it [03:33,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Validation Loss: 0.102478, Validation RMSE: 0.129336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 - Train: 224it [06:31,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.117982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 - Validation: 48it [03:34,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Validation Loss: 0.102381, Validation RMSE: 0.129129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parámetros comunes de entrenamiento\n",
    "batch_size = 8\n",
    "sample_size = 3\n",
    "num_epochs= 30\n",
    "latitudes = dataset['latitude'].values\n",
    "\n",
    "\n",
    "\n",
    "# Congelar todos los parámetros\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar los parámetros del decodificador\n",
    "for name, param in model.decoder.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "# Configuración del optimizador y función de pérdida\n",
    "optimizer_exp2 = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "criterion = torch.nn.L1Loss(reduction='none')\n",
    "\n",
    "# Entrenamiento del modelo para el Experimento 2\n",
    "train_losses_exp2, val_losses_exp2, val_rmses_exp2 = train(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer_exp2,\n",
    "    sample_size=sample_size,\n",
    "    device=device,\n",
    "    latitudes=latitudes,\n",
    ")\n",
    "\n",
    "# Guardar los resultados del Experimento 3\n",
    "results_exp2 = {\n",
    "    'train_losses': train_losses_exp2,\n",
    "    'val_losses': val_losses_exp2,\n",
    "    'val_rmses': val_rmses_exp2,\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar perdidas experimento 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar las pérdidas\n",
    "plt.plot(train_losses_exp2, label='Train Loss')\n",
    "plt.plot(val_losses_exp2, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss (Experiment 2)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos modelo del experimento 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C://Users//Public//Downloads//saved_models//modelo_aurora_experimento_2_final.pth\")\n",
    "#torch.save(results_exp2, \"C://Users//Victor//deep_ocean//TFG_victor//results//results_exp2.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Resultados del Entrenamiento**\n",
    "\n",
    "A continuación se listan (en el log) las pérdidas de entrenamiento (*Train Loss*) y validación (*Validation Loss*), además del **RMSE** en validación:\n",
    "\n",
    "| Época | Train Loss  | Validation Loss | Validation RMSE |\n",
    "|-------|------------:|----------------:|----------------:|\n",
    "| 1     | 0.354691    | 0.198365        | 0.284481        |\n",
    "| 2     | 0.183708    | 0.158869        | 0.222828        |\n",
    "| 3     | 0.159673    | 0.145079        | 0.197405        |\n",
    "| 4     | 0.148059    | 0.138017        | 0.183352        |\n",
    "| 5     | 0.140948    | 0.131248        | 0.172616        |\n",
    "| 6     | 0.136244    | 0.125506        | 0.164256        |\n",
    "| 7     | 0.132888    | 0.121701        | 0.158443        |\n",
    "| 8     | 0.130393    | 0.118269        | 0.153521        |\n",
    "| 9     | 0.128464    | 0.115630        | 0.149660        |\n",
    "| 10    | 0.126948    | 0.113220        | 0.146309        |\n",
    "| 11    | 0.125688    | 0.111840        | 0.144056        |\n",
    "| 12    | 0.124661    | 0.110381        | 0.141909        |\n",
    "| 13    | 0.123785    | 0.109019        | 0.139961        |\n",
    "| 14    | 0.123042    | 0.108388        | 0.138776        |\n",
    "| 15    | 0.122406    | 0.107188        | 0.137169        |\n",
    "| 16    | 0.121834    | 0.106962        | 0.136506        |\n",
    "| 17    | 0.121374    | 0.106215        | 0.135412        |\n",
    "| 18    | 0.120911    | 0.105732        | 0.134612        |\n",
    "| 19    | 0.120449    | 0.105039        | 0.133647        |\n",
    "| 20    | 0.120185    | 0.104775        | 0.133127        |\n",
    "| 21    | 0.119847    | 0.104332        | 0.132466        |\n",
    "| 22    | 0.119574    | 0.104160        | 0.132056        |\n",
    "| 23    | 0.119307    | 0.103715        | 0.131448        |\n",
    "| 24    | 0.119062    | 0.103537        | 0.131082        |\n",
    "| 25    | 0.118846    | 0.103253        | 0.130652        |\n",
    "| 26    | 0.118658    | 0.103230        | 0.130473        |\n",
    "| 27    | 0.118462    | 0.102932        | 0.130030        |\n",
    "| 28    | 0.118215    | 0.102718        | 0.129710        |\n",
    "| 29    | 0.118125    | 0.102478        | 0.129336        |\n",
    "| 30    | 0.117982    | 0.102381        | 0.129129        |\n",
    "\n",
    "Observamos que:\n",
    "\n",
    "- La **Train Loss** inicia en \\~0.35 y va descendiendo a \\~0.118, mostrando un ajuste progresivo en el decodificador.\n",
    "- La **Validation Loss** baja desde \\~0.20 hasta \\~0.10–0.11.\n",
    "- El **Validation RMSE** pasa de \\~0.28 a \\~0.13, confirmando que el modelo reduce su error medio cuadrático sobre el conjunto de validación a medida que se entrenan las capas del decodificador.\n",
    "\n",
    "La diferencia entre las pérdidas de entrenamiento y validación se mantiene moderada, indicando un **buen equilibrio** y ausencia de sobreajuste severo. Con más épocas (o ajustes en hiperparámetros), se podría refinar todavía más.\n",
    "\n",
    "---\n",
    "\n",
    "# **Visualización de las Pérdidas**\n",
    "\n",
    "La gráfica de **Train vs Validation Loss** presenta una tendencia decreciente relativamente estable en ambas curvas, señal clara de que el entrenamiento del decodificador mejora en paralelo a la validación, sin divergencias marcadas.\n",
    "\n",
    "---\n",
    "\n",
    "# **Conclusión**\n",
    "\n",
    "Congelar la mayor parte del modelo y **entrenar solo el decodificador** con *LR=1e-4* y *batch_size=8* durante 30 épocas resulta en:\n",
    "\n",
    "1. **Disminución** notable de la pérdida de entrenamiento (de \\~0.35 a \\~0.12).\n",
    "2. **Reducción** de la pérdida y *RMSE* en validación (RMSE de \\~0.28 a \\~0.13).\n",
    "3. **Señales de estabilidad** (no hay grandes saltos ni en entrenamiento ni en validación).\n",
    "\n",
    "Este método permite reusar gran parte del conocimiento adquirido en capas iniciales, enfocándose en **refinar la predicción final**. El modelo entrenado se guarda en:\n",
    "\n",
    "```plaintext\n",
    "C://Users//Public//Downloads//saved_models//modelo_aurora_experimento_2_final.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_ocean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
